#!/usr/bin/env python3
"""
Parses GISAID's Location field (capital "L") into 4 separate fields:

    region, country, division, and location.

Expects the GISAID Location field to be formatted as

    <region> / <country> / <division> / <location>

The presence of 4 values are not guaranteed across GISAID records, so they will
default to "?" if not available.

If the Location field does not include all geolocation values, then try to parse
the optional strain field for additional location information. Strain names are
expected to be formatted as

    <subtype>/<geography>/<sample_id>/<year>

The <geography> value will only be used if it is not already included in the
values extracted from the Location field, and the <geography> value will be used as
the next missing geolocation value.

For example, the following record only has region and country in the Location field:

    {
        "Location": "North America / United States",
        "strain": "A/Baltimore/123/2025"
    }

Then the strain's geography value "Baltimore" will be returned as the division:

    {
        "region": "North America",
        "country": "United States",
        "division": "Baltimore",
        "location": "?"
    }

"""
import argparse
import re
from pathlib import Path
import sys
import csv
from typing import Iterable, Optional
from augur.io.json import dump_ndjson, load_ndjson

SCRIPT_NAME = Path(sys.argv[0]).stem
def print_err(*args):
    print(f"[{SCRIPT_NAME}] ", *args, file=sys.stderr)

DEFAULT_UNKNOWN_VALUE = ""
LOCATION_FIELDS = [
    "region",
    "country",
    "division",
    "location",
]
# <subtype>/<location>/<sample_id>/<year>
STRAIN_LOCATION_PATTERN = r".+\/(?P<location>.+)\/.+\/.+"


def parse_locations(records: Iterable,
                    location_field: str,
                    strain_field: str,
                    annotations_field: str,
                    annotations: dict[str, dict[str,str]]) -> Iterable:
    """
    Parse the *location_field* in the *records* to split it into 4 separate
    fields: region, country, division, and location.

    If the *location_field* does not include all expected values, then try to
    parse the optional *strain_field* to get more location info.

    Yields the modified records
    """
    expected_num_locations = len(LOCATION_FIELDS)
    for record in records:
        record = record.copy()

        isl = record.get(annotations_field)
        if isl is None:
            raise Exception(f"Records must have the specified annotations field: {annotations_field!r}")
        if isl in annotations:
            # use hardcoded annotation and move on - don't check for conflicts
            for field,value in annotations[isl].items():
                record[field] = value
            yield record
            continue

        gisaid_location = record.get(location_field)

        if gisaid_location is None:
            raise Exception(f"Records must have the expected location field: {location_field!r}")

        split_locations = [location.strip() for location in gisaid_location.split("/")]
        if len(split_locations) > expected_num_locations:
            print_err(
                f"The GISAID location field has more values ({split_locations!r})",
                f"than expected ({LOCATION_FIELDS!r}), the extra values will be ignored.")

        # Attempt to extract geographical info from the strain name if we don't already have all location fields
        if (len(split_locations) < expected_num_locations and 
                (strain := record.get(strain_field)) is not None and
                (strain_location := parse_location_from_strain(strain)) is not None):
            # TODO: need better fuzzy matching because the strain_location
            # can have various spellings that don't match the metadata location
            if not any([strain_location.lower() in location.lower() for location in split_locations]):
                # If the strain_location is not found in the metadata location values
                # then assume that it is more specific than the metadata locations
                # and append it to the location values to output
                split_locations.append(strain_location)

        for index, field in enumerate(LOCATION_FIELDS):
            record[field] = split_locations[index] if len(split_locations) > index else DEFAULT_UNKNOWN_VALUE

        yield record


def parse_location_from_strain(strain: str) -> Optional[str]:
    """
    Parse the location information from the given *strain*
    Expects *strain* to be formatted as

        <subtype>/<location>/<sample_id>/<year>
    """
    location = None
    matches = re.search(STRAIN_LOCATION_PATTERN, strain)
    if matches is not None:
        location = matches["location"].strip()
    return location


def read_annotations_tsv(fname: str) -> dict[str, dict[str,str]]:
    # Based on augur curate's apply_record_annotations.py
    # <https://github.com/nextstrain/augur/blob/58f8b1aea1c135f71796bc9fbd8fefe6bc9e4369/augur/curate/apply_record_annotations.py#L31C1-L41C70>
    annotations = {}
    with open(fname, 'r', newline='') as annotations_fh:
        csv_reader = csv.reader(annotations_fh, delimiter='\t')
        for row in csv_reader:
            if not row or not row[0].lstrip() or row[0].lstrip()[0] == '#':
                    continue
            if len(row)<2 or len(row)>5:
                print_err(f"WARNING: Could not decode annotation TSV line. Found {len(row)} fields, expected: 2-5." + "\t".join(row))
                continue
            row = [x.strip() for x in row]
            if any([not x for x in row]):
                print_err(f"WARNING: Empty field in TSV line; skipping." + "\t".join(row))
                continue
            isl, *parts = row
            if isl in annotations:
                print_err(f"ISL {isl} already seen in annotations TSV. Overwriting.")
            # fill in un-specified fields
            for _ in range(len(parts), len(LOCATION_FIELDS)):
                parts.append(DEFAULT_UNKNOWN_VALUE)
            annotations[isl] = {key: parts[idx] for idx, key in enumerate(LOCATION_FIELDS)}
    return annotations


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)

    parser.add_argument("--location-field", default="location",
        help="The record field containing the GISAID location")
    parser.add_argument("--strain-field",
        help="Optional record field with strain name that includes location info.")
    parser.add_argument("--annotations", metavar="TSV", 
        help="Manually curated annotations TSV file. " +
             "The first column should be the EPI_ISL, the 2nd - 5th columns represent region, country, location & division. " +
             "The 3rd-5th columns are optional, if unset the default (unknown) value will be used for that field. " +
             "Lines starting with '#' are comments.")
    parser.add_argument("--annotations-field", default="gisaid_epi_isl",
        help="The record field used match against the annotations TSV")
    args = parser.parse_args()

    annotations = read_annotations_tsv(args.annotations) if args.annotations else {}

    records = load_ndjson(sys.stdin)
    modified_records = parse_locations(
        records,
        args.location_field,
        args.strain_field,
        args.annotations_field,
        annotations)
    dump_ndjson(modified_records)
